{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c8de80",
   "metadata": {},
   "source": [
    "### 브랜드 전체 키워드 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b97c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brandkeyword = {\n",
    "                   '남자 아르기닌':['울트라아르기닌','남성효모']}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d52a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "브랜드:   남자 아르기닌\n",
      "키워드:   울트라아르기닌\n",
      "키워드:   남성효모\n"
     ]
    }
   ],
   "source": [
    "for br in brandkeyword.keys():\n",
    "    print()\n",
    "    print('브랜드:  ', br)\n",
    "    for keyword in brandkeyword[br]:\n",
    "        print('키워드:  ', keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2bf31",
   "metadata": {},
   "source": [
    "### 네이버 트래킹 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2e95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def crawl(keyword):\n",
    "    header = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "    'cache-control': 'max-age=0',\n",
    "    'cookie': 'nx_ssl=2; NNB=JCBOWSM5V3GGE; autocomplete=use; AD_SHP_BID=9; _ga=GA1.2.1164695733.1657581707; ncpa=95694|l5he3m5s|7918e86803866ebcebed07f9bd04a8f0e2aca26d|95694|684a7e7d3224595049682f2307a9f22892167a99:628226|l5he7pjc|8fedfc6ac1b0c11c21fdef3ef76f8590e761a269|s_2c8b6ed8b5818|41ebe434fb086f6d675ef212c1060077f45e48cf:692176|l5hf3360|32152b4df28dee72ac67aa59f9f1a81394112511|s_3384d4e2f4bc9|ad9b61abc92ca620867ffe2c6c38427095bc8d2c; NaverSuggestUse=use%26unuse; nid_inf=1733643794; NID_AUT=JLVAAKb4ILh68mRXBXne7DHBpBoC0Ity1GENP5nd7nU1dt+j7FRZbIFGScB7aNGZ; NID_JKL=zTfjaTc1rrIQGVGMNt+mHdJokT1ixuQnbq9LBxkzEzU=; spage_uid=; sus_val=XXHHJzm5614a3gxX9E8bUrbI; NID_SES=AAABo+5PzlcBGyZepMwt9TXG5g8t4O4Z5dJ19iAMO8YZej3kc80LyFQLIKGXCKzfMm6SbibKHs0/KledHneQvFogyKXUHBSWXygygeLUCXj2yNpRs3LbQTjAIPmSy6dmPn3FbqVrdsjFYf9/9zWOkLF0CGRz36HGyBVMyOmT8fnYjik0qyEaP7AEQl9SsCZbLbs7A4RmWQaSuWR6TKkhOYBmLA3l+DdkLoOrA3GjiFFUN5H17RbSTpzaXLRXTj8muFuBWFtltWXnsdTX9WsBQhM2yo8j4oybhA274H14uaLAUU0Dy63TL+2gNCEocVqGKjM/yRIfDaTZTLxplfjlBDVBBqG4IQUpMaN6Hzqgd0loVnO/tJF7mASOATTkWxJUqtDu3vVP0s0lUKVNR52b2F08jd8wrYaHgjbtv06MJyVAGnatb6/nECcIjd64tncODJVyM0RDocEGTmJQDEIllaDIPtRcmgpcFVST/crv5CckRuTFG3gbrA5MsUKro2oLJyEGRYI00hLy8uidQZL92ya5lcWWGFefhyd2tTLuin8/5sq439p8+AW2S8bjxUozcK8naA==',\n",
    "    'referer': 'https://shopping.naver.com/home/p/index.naver',\n",
    "    'sec-ch-ua': '\".Not/A)Brand\";v=\"99\", \"Google Chrome\";v=\"103\", \"Chromium\";v=\"103\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'\n",
    "    }    \n",
    "    if 'mobile' in kind and 'powerlink' not in kind:\n",
    "        url = \"https://msearch.shopping.naver.com/search/all?sort=rel&pagingIndex={}&pagingSize=40&viewType=lst&productSet=total&query={}&origQuery={}&frm=NVSHPAG\".format(\n",
    "            pageNum, keyword, keyword)\n",
    "    elif 'pc' in kind and 'powerlink' not in kind:\n",
    "        url = \"https://search.shopping.naver.com/search/all.nhn?origQuery={}&pagingIndex={}&pagingSize=40&viewType=list&sort=rel&frm=NVSHPAG&query={}\".format(\n",
    "            keyword, pageNum, keyword)\n",
    "    elif 'mobile' in kind and 'powerlink' in kind:\n",
    "        url = \"https://m.search.naver.com/search.naver?sm=mtp_hty.top&where=m&query={}\".format(keyword)\n",
    "    elif 'pc' in kind and 'powerlink' in kind:\n",
    "        url = \"https://search.naver.com/search.naver?sm=top_hty&fbm=0&ie=utf8&query={}\".format(keyword)\n",
    "    data = requests.get(url, headers=header)\n",
    "    time.sleep(2)\n",
    "    return data.content\n",
    "\n",
    "def powergetProductInfo(ads):\n",
    "    if 'pc' in kind:\n",
    "        title = ads.find('div', {'class': 'lnk_tit'}).text\n",
    "        url = ads.find('div', {'class': 'url_area'}).find('a', {'class':'lnk_url'}).text\n",
    "        return {\"keyword\": keyword, \"url\": url, \"title\": title}\n",
    "    elif 'mobile' in kind:\n",
    "        title = ads.find('span', {'class':'tit'}).text\n",
    "        url = ads.find('span', {'class':'url'}).text\n",
    "        return {\"keyword\": keyword, \"url\": url, \"title\": title}\n",
    "\n",
    "def getProductInfo(li):\n",
    "    img = li['item']['productName']\n",
    "    priceReload = li['item']['price']\n",
    "    ranks = li['item']['rank']\n",
    "    try:\n",
    "        adsNum = li['item']['adId']\n",
    "    except KeyError:\n",
    "        adsNum = 'No-Ads'\n",
    "    try:\n",
    "        if type(li['item']['lowMallList']) == list:\n",
    "            collection= li['item']['lowMallList']\n",
    "            for i in range(1):\n",
    "                aTit = '(가격비교묶기) ' + collection[i]['name']\n",
    "                adsNum = 'No-Ads'\n",
    "                id = collection[i]['mallPid']\n",
    "        else:\n",
    "            aTit = li['item']['mallName']\n",
    "            id = li['item']['mallProductId']\n",
    "    except KeyError:\n",
    "        id = 'None'\n",
    "    return {\"ads\": adsNum, \"keyword\": keyword, \"name\": img, \"price\": priceReload, \"shopper\": aTit, \"productID\": id, \"rank\": ranks}\n",
    "\n",
    "\n",
    "def parse(pageString):\n",
    "    if 'mobile' in kind and 'powerlink' not in kind:\n",
    "        products = []\n",
    "        bsObj = BeautifulSoup(pageString, 'html.parser')\n",
    "        data = bsObj.findAll('script', {'type': 'application/json'})\n",
    "        for datas in data:\n",
    "            ojson = json.loads(datas.text)['props']['pageProps']['initialState']\n",
    "            ojson = json.loads(ojson)['compositeProducts']['list']\n",
    "            for li in ojson:\n",
    "                product = getProductInfo(li)\n",
    "                products.append(product)\n",
    "            return products\n",
    "    elif 'pc' in kind and 'powerlink' not in kind:\n",
    "        products = []\n",
    "        bsObj = BeautifulSoup(pageString, 'html.parser')\n",
    "        data = bsObj.findAll('script', {'type': 'application/json'})\n",
    "        for datas in data:\n",
    "            ojson = json.loads(datas.string)['props']['pageProps']['initialState']['products']['list']\n",
    "            for li in ojson:\n",
    "                product = getProductInfo(li)\n",
    "                products.append(product)\n",
    "        return products\n",
    "    elif 'mobile' in kind and 'powerlink' in kind:\n",
    "        products = []\n",
    "        bsObj = BeautifulSoup(pageString, 'html.parser')\n",
    "        lis = bsObj.findAll('ul', {\"id\": re.compile(\"power_link_body\")})\n",
    "        for li in lis:\n",
    "            ads_list = li.findAll('div', {'class':'total_wrap'})\n",
    "        for ads in ads_list:\n",
    "            product = powergetProductInfo(ads)\n",
    "            products.append(product)\n",
    "        return products\n",
    "    elif 'pc' in kind and 'powerlink' in kind:\n",
    "        products = []\n",
    "        bsObj = BeautifulSoup(pageString, 'html.parser')\n",
    "        lis = bsObj.findAll('div', {'id': 'power_link_body'})\n",
    "        for li in lis:\n",
    "            ads_list = li.findAll('div', {'class': 'inner'})\n",
    "        for ads in ads_list:\n",
    "            product = powergetProductInfo(ads)\n",
    "            products.append(product)\n",
    "        return products\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8543536",
   "metadata": {},
   "source": [
    "### 쿠팡, 옥션, 11번가, 지마켓 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe02e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests \n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "errorlst = []\n",
    "for br in brandkeyword.keys():\n",
    "    print()\n",
    "    print('브랜드:  ', br)\n",
    "    \n",
    "    with pd.ExcelWriter('{} 노출 트래킹 결과_{}.xlsx'.format(br, datetime.now().strftime('%y%m%d'))) as writer:\n",
    "        for jojo in range(len(brandkeyword[br])):\n",
    "            keyword = brandkeyword[br][jojo]\n",
    "            keyworddf = pd.DataFrame()\n",
    "            print('키워드:  ', keyword)\n",
    "\n",
    "        ######\n",
    "        # 네이버 시작\n",
    "        ######\n",
    "            keyword = brandkeyword[br][jojo]\n",
    "            naverqq = pd.DataFrame()\n",
    "            result = pd.DataFrame()\n",
    "            for kind in ['pc','mobile']:\n",
    "                brand = br\n",
    "                print(kind, keyword, \" 서치중\")\n",
    "                pageNum = 1\n",
    "                ad_rank = 1\n",
    "                rank = 1\n",
    "                pc_product = pd.DataFrame()\n",
    "                mobile_product = pd.DataFrame()\n",
    "                for loop in range(1):\n",
    "                    pageString = crawl(keyword) # 키워드를 크롤링\n",
    "                    products = parse(pageString)\n",
    "                    for product in products:\n",
    "                        if 'pc' in kind: #pc 오가닉\n",
    "                            if product['ads'] != 'No-Ads':\n",
    "                                pc_product = pc_product.append(pd.DataFrame([['광고', brand, keyword, pageNum, rank, product['name'], product['productID'], product['price'], product['shopper'], product['ads'], ad_rank]], columns=['구분', '브랜드', '키워드', '페이지수', '위치', '상품명', '상품ID', '가격', '셀러명', '광고아이디', '광고/오가닉순위']))\n",
    "                                ad_rank += 1\n",
    "                                rank += 1\n",
    "                            else:\n",
    "                                pc_product = pc_product.append(pd.DataFrame([['', brand, keyword, pageNum, rank, product['name'], product['productID'], product['price'], product['shopper'], product['ads'], product['rank']]], columns=['구분', '브랜드', '키워드', '페이지수', '위치', '상품명', '상품ID', '가격', '셀러명', '광고아이디', '광고/오가닉순위']))\n",
    "                                rank += 1\n",
    "                            if len(pc_product) > 0:\n",
    "                                pc_product['분류'] = '네이버_PC'\n",
    "                                result = pc_product\n",
    "\n",
    "                        else: #모바일 오가닉\n",
    "                            if product['ads'] != 'No-Ads':\n",
    "                                mobile_product = mobile_product.append(pd.DataFrame([['광고', brand, keyword, pageNum, rank, product['name'], product['productID'], product['price'], product['shopper'], product['ads'], ad_rank]], columns=['구분', '브랜드', '키워드', '페이지수', '위치', '상품명', '상품ID', '가격', '셀러명', '광고아이디', '광고/오가닉순위']))\n",
    "                                ad_rank += 1\n",
    "                                rank += 1\n",
    "                            else:\n",
    "                                mobile_product = mobile_product.append(pd.DataFrame([['', brand, keyword, pageNum, rank, product['name'], product['productID'], product['price'], product['shopper'], product['ads'], product['rank']]], columns=['구분', '브랜드', '키워드', '페이지수', '위치', '상품명', '상품ID', '가격', '셀러명', '광고아이디', '광고/오가닉순위']))\n",
    "                                rank += 1\n",
    "                            if len(mobile_product) > 0:\n",
    "                                mobile_product['분류'] = '네이버_모바일'\n",
    "                                result = mobile_product\n",
    "                naverqq = pd.concat([naverqq, result])\n",
    "            try:\n",
    "                naverqq = naverqq[['위치','분류','상품명','상품ID','가격', '셀러명', '구분']]\n",
    "                naverqq.columns = ['index', '채널','상품명', '상품ID', '가격', '판매자', '광고여부']\n",
    "            except:\n",
    "                naverqq = pd.DataFrame()\n",
    "                errorlst.append({'브랜드': br,'채널':'네이버','키워드':brandkeyword[br][jojo]})\n",
    "\n",
    "        #######\n",
    "        # 쿠팡 시작\n",
    "        #######\n",
    "            def getPageString(url):\n",
    "                data = requests.get(url, headers = headers)\n",
    "                return data.content\n",
    "            \n",
    "            headers = {\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'accept-encoding': 'gzip, deflate, br',\n",
    "            'accept-language': 'en-US,en;q=0.9',\n",
    "            'cache-control': 'no-cache',\n",
    "            'cookie': 'mid=YfNn_wAEAAGcsrsw8WpRAvPXFgPo; ig_did=29AF9B8C-C62A-4EE5-BAC7-3C081EA9AB8F; ig_nrcb=1; csrftoken=W9GZ945eA65uZA87rBM7wnxZ8V4pj7wN; ds_user_id=1305778462; sessionid=1305778462%3AGNkC0wuSqS3mcZ%3A11; shbid=\"8520\\0541305778462\\0541674879758:01f7aceb492e0f47a3596c0a6dc1d9133e175142c2b6268267277abd1281e7dc2144372b\"; shbts=\"1643343758\\0541305778462\\0541674879758:01f73164fb8aef28db280f397fceae005a5cbc050174dff1e5d3710a1c86b8b02c9e022f\"; rur=\"VLL\\0541305778462\\0541674879768:01f70cac8366a361d7456f77ac0111584b70d57e0a8ad8b19b2c4fca58b7b9cad51b638c\"',\n",
    "            'pragma': 'no-cache',\n",
    "            'sec-ch-ua': '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"97\", \"Chromium\";v=\"97\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"macOS\"',\n",
    "            'sec-fetch-dest': 'document',\n",
    "            'sec-fetch-mode': 'navigate',\n",
    "            'sec-fetch-site': 'none',\n",
    "            'sec-fetch-user': '?1',\n",
    "            'upgrade-insecure-requests': '1',\n",
    "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'\n",
    "            }\n",
    "            print('쿠팡')\n",
    "\n",
    "            def vendor(link):\n",
    "                qq = link\n",
    "                qq = 'https://www.coupang.com/vp/' + qq.split(\"/vm/\")[-1]\n",
    "                res1 = requests.get(qq, headers = headers).text\n",
    "                soup1 = BeautifulSoup(res1, 'html.parser')\n",
    "                tt = soup1.find_all('script')[4].text.split(\"exports.sdp = \")[-1].split(\";\\n        exports\")[0]\n",
    "                try:\n",
    "                    pp = json.loads(tt)  \n",
    "                    try:\n",
    "                        return pp['vendor']['name']\n",
    "                    except:\n",
    "                        return '쿠팡'\n",
    "                except:\n",
    "                    return '추적 문제'\n",
    "\n",
    "\n",
    "            search = keyword\n",
    "            url = \"https://m.coupang.com/nm/search?q={}\".format(search)\n",
    "\n",
    "            pageString = getPageString(url)\n",
    "            soup = BeautifulSoup(pageString, \"html.parser\")\n",
    "            # a = soup.find_all('div',{'class':'details'})\n",
    "            a = soup.find_all('li',{'class':'plp-default__item'})\n",
    "            pageone = []\n",
    "            try:\n",
    "                for data in a:\n",
    "                    link = data.find('a')['href']\n",
    "                    sku = link.split('/')[-1].split(\"?\")[0]\n",
    "                    try:\n",
    "                        ad = data.find(\"span\",{'class':'ad-badge-text'}).text\n",
    "                    except AttributeError:\n",
    "                        ad = data.find(\"span\",{'class':'ad-badge-text'})\n",
    "                    title = data.find('strong',{'class':'title'}).text\n",
    "                    try:\n",
    "                        discount = data.find(\"span\", {'class':'percentage'}).text\n",
    "                    except AttributeError:\n",
    "                        discount = data.find(\"span\", {'class':'percentage'})\n",
    "                    try:\n",
    "                        ori_price = data.find(\"strong\",{'class':'price'}).text.split('원')[0]        \n",
    "                    except AttributeError:        \n",
    "                        ori_price = data.find(\"strong\",{'class':'price'})\n",
    "                    dis_price = data.find(\"div\",{\"class\":\"discount-price\"}).find(\"strong\").text\n",
    "                    pageone.append({'상품명':title,'상품ID':sku,'할인율':discount,'정가':ori_price,'할인가':dis_price,'광고유무':ad,'링크':link})\n",
    "                pageonedf = pd.DataFrame(pageone)\n",
    "\n",
    "                pageonedf['판매자'] = pageonedf['링크'].apply(lambda x: vendor(x))\n",
    "                pageonedf = pageonedf[['상품명', '상품ID', '할인율', '정가', '할인가', '광고유무', '판매자']]\n",
    "                pageonedf['채널'] = '쿠팡'\n",
    "                pageonedf = pageonedf[['채널','상품명', '상품ID', '할인가', '판매자','광고유무']]\n",
    "                pageonedf.columns = ['채널','상품명', '상품ID', '가격', '판매자', '광고여부']\n",
    "                coupang = pageonedf\n",
    "            except:\n",
    "                errorlst.append({'브랜드': br,'채널':'쿠팡','키워드':brandkeyword[br][jojo]})\n",
    "                coupang = pd.DataFrame()\n",
    "\n",
    "        #######\n",
    "        # 옥션 시작\n",
    "        #######\n",
    "            # headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}\n",
    "            print('옥션')\n",
    "            headers = {\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'accept-encoding': 'gzip, deflate, br',\n",
    "            'accept-language': 'en-US,en;q=0.9',\n",
    "            'cache-control': 'no-cache',\n",
    "            'cookie': 'mid=YfNn_wAEAAGcsrsw8WpRAvPXFgPo; ig_did=29AF9B8C-C62A-4EE5-BAC7-3C081EA9AB8F; ig_nrcb=1; csrftoken=W9GZ945eA65uZA87rBM7wnxZ8V4pj7wN; ds_user_id=1305778462; sessionid=1305778462%3AGNkC0wuSqS3mcZ%3A11; shbid=\"8520\\0541305778462\\0541674879758:01f7aceb492e0f47a3596c0a6dc1d9133e175142c2b6268267277abd1281e7dc2144372b\"; shbts=\"1643343758\\0541305778462\\0541674879758:01f73164fb8aef28db280f397fceae005a5cbc050174dff1e5d3710a1c86b8b02c9e022f\"; rur=\"VLL\\0541305778462\\0541674879768:01f70cac8366a361d7456f77ac0111584b70d57e0a8ad8b19b2c4fca58b7b9cad51b638c\"',\n",
    "            'pragma': 'no-cache',\n",
    "            'sec-ch-ua': '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"97\", \"Chromium\";v=\"97\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"macOS\"',\n",
    "            'sec-fetch-dest': 'document',\n",
    "            'sec-fetch-mode': 'navigate',\n",
    "            'sec-fetch-site': 'none',\n",
    "            'sec-fetch-user': '?1',\n",
    "            'upgrade-insecure-requests': '1',\n",
    "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'\n",
    "            }\n",
    "\n",
    "            def getPageString(url):\n",
    "                data = requests.get(url, headers = headers)\n",
    "                return data.content\n",
    "\n",
    "            url = 'http://browse.auction.co.kr/m/search?keyword={}'.format(keyword)\n",
    "            urlpageString = getPageString(url)\n",
    "            soup = BeautifulSoup(urlpageString, \"html.parser\")\n",
    "            soup\n",
    "            a = soup.find_all(\"div\",{'class':'component component--item_card type--general'})\n",
    "            onepage = []\n",
    "            try:\n",
    "                for data in a:\n",
    "                    title = data.find(\"span\",{'class':'text--title'}).text\n",
    "                    sku = data.find('a',{'class':'link--itemcard'})['href'].split(\"itemno\")[-1].split('&data')[0]\n",
    "                    price = data.find(\"strong\",{'class':'text--price_seller'}).text\n",
    "                    try:\n",
    "                        seller = data.find('a',{'class':'link--shop'}).find(\"span\",{'class':'text'}).text\n",
    "                    except:\n",
    "                        seller = data.find('a',{'class':'link--shop'}).find(\"span\",{'class':'img'}).text\n",
    "                    try:\n",
    "                        ad = data.find('div',{'class':'section--component_title'}).text\n",
    "                    except:\n",
    "                        ad = data.find('div',{'class':'section--component_title'})\n",
    "                    onepage.append({'상품명':title,'상품ID':sku,'가격':price,'판매자':seller,'광고':ad})\n",
    "                df = pd.DataFrame(onepage)\n",
    "                k = '광고'\n",
    "                for i in range(len(df)):\n",
    "                    if df.loc[i,'광고'] != '일반등록':\n",
    "                        df.loc[i,'광고'] = k\n",
    "                        df.loc[i,'상품ID'] = df.loc[i,'상품ID'].split(\"%3d\")[-1]\n",
    "                    else:\n",
    "                        k = ''\n",
    "                        df.loc[i,'광고'] = k\n",
    "                    if df.loc[i,'광고'] == '':\n",
    "                        df.loc[i,'상품ID'] = df.loc[i,'상품ID'].split(\"=\")[-1]\n",
    "                df['채널'] = '옥션'\n",
    "                df = df[['채널','상품명', '상품ID', '가격', '판매자', '광고']]\n",
    "                df.columns = ['채널','상품명', '상품ID', '가격', '판매자', '광고여부']\n",
    "                auction = df\n",
    "            except:\n",
    "                errorlst.append({'브랜드': br,'채널':'옥션','키워드':brandkeyword[br][jojo]})\n",
    "                auction = pd.DataFrame()\n",
    "        #######\n",
    "        # 지마켓 시작\n",
    "        #######\n",
    "            # headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}\n",
    "            print('지마켓')\n",
    "            url = 'http://browse.gmarket.co.kr/m/search?keyword={}'.format(keyword)\n",
    "            # url = 'http://browse.gmarket.co.kr/m/search?keyword=%EC%A0%90%ED%94%84%EC%97%85%ED%95%98%EC%9D%B4%EC%A0%95'\n",
    "            urlpageString = getPageString(url)\n",
    "            soup = BeautifulSoup(urlpageString, \"html.parser\")\n",
    "            soup\n",
    "            a = soup.find_all(\"div\",{'class':'box__component box__component-itemcard box__component-itemcard--general'})\n",
    "            onepage = []\n",
    "            try:\n",
    "                for data in a:\n",
    "                    title = data.find(\"span\",{'class':'text__item'}).text\n",
    "                    sku = data.find('a',{'class':'link__item'})['href'].split(\"goodscode=\")[-1]\n",
    "                    link = data.find('a',{'class':'link__item'})['href']\n",
    "                    price = data.find(\"strong\",{'class':'text text__value'}).text\n",
    "                    try:\n",
    "                        seller = data.find('a',{'class':'link__shop'}).find(\"span\",{'class':'text__seller'}).text\n",
    "                    except:\n",
    "                        seller = data.find('a',{'class':'link__shop'}).find(\"span\",{'class':'text__seller'})\n",
    "                    try:\n",
    "                        ad = data.find('p',{'class':'text__title'}).text\n",
    "                    except:\n",
    "                        ad = data.find('p',{'class':'text__title'})\n",
    "                    onepage.append({'상품명':title,'상품ID':str(sku),'가격':price,'판매자':seller,'광고':ad})\n",
    "                df = pd.DataFrame(onepage)\n",
    "                k = '광고'\n",
    "                for i in range(len(df)):\n",
    "                    if df.loc[i,'광고'] != '일반상품':\n",
    "                        df.loc[i,'광고'] = k\n",
    "                        df.loc[i,'상품ID'] = df.loc[i,'상품ID'].split(\"%3d\")[-1]\n",
    "                    else:\n",
    "                        k = ''\n",
    "                        df.loc[i,'광고'] = k\n",
    "                    if df.loc[i,'광고'] == '':\n",
    "                        df.loc[i,'상품ID'] = df.loc[i,'상품ID'].split(\"=\")[-1]\n",
    "\n",
    "                df['채널'] = '지마켓'\n",
    "                df = df[['채널','상품명', '상품ID', '가격', '판매자', '광고']]\n",
    "                df.columns = ['채널','상품명', '상품ID', '가격', '판매자', '광고여부']\n",
    "                gmarket = df\n",
    "            except:\n",
    "                errorlst.append({'브랜드': br,'채널':'지마켓','키워드':brandkeyword[br][jojo]})\n",
    "                gmarket = pd.DataFrame()\n",
    "\n",
    "        #######\n",
    "        # 11번가 시작\n",
    "        #######\n",
    "            print('11번가')\n",
    "            keyword1 = keyword\n",
    "            ll = (urllib.parse.quote(keyword1,safe='')).split('%')\n",
    "            qq = ''\n",
    "            for l in ll:\n",
    "                qq += l\n",
    "                qq += '%25'\n",
    "            keyword = qq[:-3]\n",
    "            keyword\n",
    "\n",
    "            site_url = 'http://search.11st.co.kr/MW/search?searchKeyword={}'.format(keyword)\n",
    "\n",
    "            res = requests.get(site_url).text\n",
    "            soup = BeautifulSoup(res,'html.parser')\n",
    "            a = soup.findAll('script')[0].text.split(\"window.N11ST.model =  \")[-1].split(\"\\n    console.time(\\'HTML to Render\\')\")[0][:-1].split(';\\n\\n')[0]\n",
    "            a = a.replace(';\\n        console.log(\\'SCHFE-10-3\\')\\n   ','')\n",
    "            b = json.loads(a)\n",
    "            k = []\n",
    "            try:\n",
    "                for pp in range(len(b['data'])):\n",
    "                    try:\n",
    "                        for info in b['data'][pp]['items']:\n",
    "                            title = info['title']\n",
    "                            link = info['linkUrl']\n",
    "                            sku = str(info['id'])\n",
    "                            price = info['finalPrc']\n",
    "                            ad = info['logData']['area']\n",
    "                            if 'https://catalog.11st.co.kr/MW/Catalog/catalogDetail.tmall?catalogNo' in link:\n",
    "                                sku = link\n",
    "                                CtgrNo = link.split('catalogNo=')[-1].split(\"&\")[-1].split(\"=\")[-1]\n",
    "                            k.append({'상품명':title,'상품ID':sku,'가격':price,'광고':ad})\n",
    "                    except:\n",
    "                        pass\n",
    "                adf = pd.DataFrame(k)\n",
    "                adf['판매자'] = ''\n",
    "                adf['광고여부'] = ''\n",
    "                for i in range(len(adf)):\n",
    "                    if 'https://catalog.11st.co.kr/MW/Catalog/catalogDetail.tmall?catalogNo' in str(adf.loc[i,'상품ID']):\n",
    "                        catalogNo = adf.loc[i,'상품ID'].split('catalogNo=')[-1].split(\"&\")[0]\n",
    "                        CtgrNo = adf.loc[i,'상품ID'].split('catalogNo=')[-1].split(\"&\")[-1].split(\"=\")[-1]\n",
    "                        url = 'https://catalog.11st.co.kr/api/Catalog/ajaxDetailList.tmall?catalogNo={}&sellerNos=&trTypeCd=MAS51&trCtgrNo={}'.format(catalogNo, CtgrNo)\n",
    "                        res1 = requests.get(url)\n",
    "                        soup1 = res1.json()\n",
    "                        try:\n",
    "                            seller = soup1['data'][1]['priceCompare']['packageInfoList'][0]['prdList'][0]['memNm']\n",
    "                            sku = soup1['data'][1]['priceCompare']['packageInfoList'][0]['prdList'][0]['prdNo']\n",
    "                        except:\n",
    "                            seller = soup1['data'][1]['priceCompare']['prdList'][0]['memNm']\n",
    "                            sku = soup1['data'][1]['priceCompare']['prdList'][0]['prdNo']\n",
    "                        adf.loc[i,'상품ID'] = str(sku)\n",
    "                        adf.loc[i,'판매자'] = seller\n",
    "                        if adf.loc[i,'광고'] == 'catalog_compare':\n",
    "                            adf.loc[i,'광고여부'] = '가격비교 컬럼'\n",
    "                        else:\n",
    "                            adf.loc[i,'광고여부'] = '가격비교'\n",
    "                    else:\n",
    "                        url = 'https://www.11st.co.kr/products/{}?trTypeCd=MAS24&trCtgrNo={}'.format(adf.loc[i,'상품ID'],CtgrNo)\n",
    "                        res1 = requests.get(url).text\n",
    "                        res1 = BeautifulSoup(res1,'html.parser')\n",
    "                        seller = res1.find(\"h1\", {'class':\"c_product_store_title\"}).find(\"a\").text.replace(\" \",'').replace(\"\\n\",'')        \n",
    "                        adf.loc[i,'판매자'] = seller\n",
    "                        if 'focus' in adf.loc[i,'광고'] or 'plus' in adf.loc[i,'광고']:\n",
    "                            adf.loc[i,'광고여부'] = '광고'\n",
    "\n",
    "                adf['채널'] = '11번가'\n",
    "                adf = adf[['채널','상품명', '상품ID', '가격', '판매자', '광고여부']]\n",
    "                street = adf\n",
    "            except:\n",
    "                errorlst.append({'브랜드': br,'채널':'11번가','키워드':brandkeyword[br][jojo]})\n",
    "                street = pd.DataFrame()\n",
    "            keyword = brandkeyword[br][jojo]\n",
    "    \n",
    "        ######\n",
    "        ##티몬\n",
    "        ######\n",
    "            print('티몬')\n",
    "            headers = {\n",
    "            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'accept-encoding': 'gzip, deflate, br',\n",
    "            'accept-language': 'en-US,en;q=0.9',\n",
    "            'cache-control': 'no-cache',\n",
    "            'referer': 'http://m.search.tmon.co.kr/search?',\n",
    "            'cookie': 'mid=YfNn_wAEAAGcsrsw8WpRAvPXFgPo; ig_did=29AF9B8C-C62A-4EE5-BAC7-3C081EA9AB8F; ig_nrcb=1; csrftoken=W9GZ945eA65uZA87rBM7wnxZ8V4pj7wN; ds_user_id=1305778462; sessionid=1305778462%3AGNkC0wuSqS3mcZ%3A11; shbid=\"8520\\0541305778462\\0541674879758:01f7aceb492e0f47a3596c0a6dc1d9133e175142c2b6268267277abd1281e7dc2144372b\"; shbts=\"1643343758\\0541305778462\\0541674879758:01f73164fb8aef28db280f397fceae005a5cbc050174dff1e5d3710a1c86b8b02c9e022f\"; rur=\"VLL\\0541305778462\\0541674879768:01f70cac8366a361d7456f77ac0111584b70d57e0a8ad8b19b2c4fca58b7b9cad51b638c\"',\n",
    "            'pragma': 'no-cache',\n",
    "            'sec-ch-ua': '\" Not;A Brand\";v=\"99\", \"Google Chrome\";v=\"97\", \"Chromium\";v=\"97\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"macOS\"',\n",
    "            'sec-fetch-dest': 'document',\n",
    "            'sec-fetch-mode': 'navigate',\n",
    "            'sec-fetch-site': 'none',\n",
    "            'sec-fetch-user': '?1',\n",
    "            'upgrade-insecure-requests': '1',\n",
    "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36'\n",
    "            }\n",
    "            keyword = brandkeyword[br][jojo]\n",
    "            url = 'http://m.search.tmon.co.kr/api/search/v4/deals?keyword={}'.format(keyword)\n",
    "            urlpageString = requests.get(url,headers=headers)\n",
    "            soup = urlpageString.json()\n",
    "            a = soup['data']['searchDeals']\n",
    "            prolst = []\n",
    "            i = 1\n",
    "            try:\n",
    "                for data in a:\n",
    "                    if data['searchDealResponse']['searchInfo']['isOptionDeal'] == False:\n",
    "                        sku = data['searchDealResponse']['searchInfo']['id']\n",
    "                        name = data['searchDealResponse']['dealInfo']['titleName']\n",
    "                        price = data['searchDealResponse']['dealInfo']['priceInfo']['price']\n",
    "                        partnerno = data['searchDealResponse']['dealInfo']['partnerNo']\n",
    "                        tt = 'http://mobile.tmon.co.kr/api/detail/direct/v1/detailapi/api/partner/info/{}?mainDealNo={}'.format(partnerno,sku)\n",
    "                        urlpageString1 = requests.get(tt,headers=headers)\n",
    "                        seller = BeautifulSoup(urlpageString1.content,'html.parser').find(\"ecaccountnm\").text\n",
    "\n",
    "                        try:\n",
    "                            ad = data['searchDealResponse']['dealInfo']['admonUrl']\n",
    "                            ad = '광고'\n",
    "                        except:\n",
    "                            ad = ''\n",
    "                        prolst.append({'순위':i, '채널':'티몬','상품ID':sku, '상품명':name, '가격':price,'광고':ad, '판매자':seller})\n",
    "                        i += 1\n",
    "                prodf = pd.DataFrame(prolst)\n",
    "                tmondf = prodf\n",
    "                tmondf.columns = ['index', '채널', '상품ID', '상품명', '가격', '광고여부', '판매자']\n",
    "                tmondf = tmondf[['채널','index','상품명', '상품ID', '가격', '판매자', '광고여부']]\n",
    "            except:\n",
    "                errorlst.append({'브랜드': br,'채널':'티몬','키워드':brandkeyword[br][jojo]})\n",
    "                tmondf = pd.DataFrame()\n",
    "                \n",
    "        #####\n",
    "        ##위메프\n",
    "        #####\n",
    "            print('위메프')\n",
    "            keyword = brandkeyword[br][jojo]\n",
    "            url = 'https://search.wemakeprice.com/api/wmpsearch/api/v3.0/wmp-search/search.json?searchType=DEFAULT&search_cate=top&keyword={}'.format(keyword)\n",
    "            urlpageString = requests.get(url)\n",
    "            soup = urlpageString.json()\n",
    "            #### 광고\n",
    "            adlst = []\n",
    "            ### 광고용\n",
    "            try:\n",
    "                k = soup['data']['adTargetClick']['data']['deals']\n",
    "            except:\n",
    "                print('광고없음')\n",
    "            ###일반용\n",
    "            try:\n",
    "                a = soup['data']['deals']\n",
    "            except:\n",
    "                print('일반 없음')\n",
    "            try:\n",
    "                for data in k:\n",
    "                    channel = '위메프'\n",
    "                    name = data['dispNm']\n",
    "                    if data['discountPrice']==None:\n",
    "                        price = data['salePrice']\n",
    "                    else:\n",
    "                        price = data['discountPrice']\n",
    "                    sku =   data['link']['value']\n",
    "                    try:\n",
    "                        conditionid = data['link']['option']['query']['buyingConditionId']\n",
    "                        catalognum = data['catalog']['catalogNo']\n",
    "                        tt = 'https://front.wemakeprice.com/api/cataloglisting/v2/catalog/{}.json?buycdtId={}'.format(catalognum, conditionid)\n",
    "                        urlpageString1 = requests.get(tt)\n",
    "                        soup1 = urlpageString1.json()\n",
    "                        seller = soup1['data']['prodLists'][0]['list'][0]['sellerNm']\n",
    "                    except:\n",
    "                        tt = 'https://front.wemakeprice.com/product/{}'.format(sku)\n",
    "                        def getPageString(url):\n",
    "                            data = requests.get(url, headers = headers)\n",
    "                            return data.content\n",
    "\n",
    "                        urlpageString = getPageString(tt)\n",
    "                        soup = BeautifulSoup(urlpageString, \"html.parser\")\n",
    "                        seller = soup.find('body').find_all('table',{'class':'table_info'})[5].find('span').text\n",
    "\n",
    "                    adlst.append({'상품명':name,'상품ID':sku,'가격':price,'판매자':seller,'광고여부':'광고'})\n",
    "\n",
    "                u = pd.DataFrame(adlst)\n",
    "\n",
    "                ### 일반\n",
    "\n",
    "                prolst = []\n",
    "                for data in a:\n",
    "                    channel = '위메프'\n",
    "                    name = data['dispNm']\n",
    "                    if data['discountPrice']==None:\n",
    "                        price = data['salePrice']\n",
    "                    else:\n",
    "                        price = data['discountPrice']\n",
    "                    sku =   data['link']['value']\n",
    "                    try:\n",
    "                        conditionid = data['link']['option']['query']['buyingConditionId']\n",
    "                        catalognum = data['catalog']['catalogNo']\n",
    "                        tt = 'https://front.wemakeprice.com/api/cataloglisting/v2/catalog/{}.json?buycdtId={}'.format(catalognum, conditionid)\n",
    "                        urlpageString1 = requests.get(tt)\n",
    "                        soup1 = urlpageString1.json()\n",
    "                        seller = soup1['data']['prodLists'][0]['list'][0]['sellerNm']\n",
    "                    except:\n",
    "                        tt = 'https://front.wemakeprice.com/product/{}'.format(sku)\n",
    "                        def getPageString(url):\n",
    "                            data = requests.get(url, headers = headers)\n",
    "                            return data.content\n",
    "\n",
    "                        urlpageString = getPageString(tt)\n",
    "                        soup = BeautifulSoup(urlpageString, \"html.parser\")\n",
    "                        try:\n",
    "                            seller = soup.find('body').find_all('table',{'class':'table_info'})[3].find('span').text\n",
    "                            if '배송비' in seller:\n",
    "                                seller = ''\n",
    "                        except:\n",
    "                            seller = ''\n",
    "                    prolst.append({'상품명':name,'상품ID':sku,'가격':price,'판매자':seller,'광고여부':''})\n",
    "\n",
    "                prodf = pd.DataFrame(prolst)\n",
    "                wemakedf = pd.concat([u, prodf])\n",
    "                wemakedf.reset_index(inplace=True)\n",
    "                wemakedf = wemakedf[['상품명', '상품ID', '가격', '판매자', '광고여부']]\n",
    "                wemakedf.reset_index(inplace=True)\n",
    "                wemakedf['index'] = wemakedf['index'].apply(lambda x: x+1)\n",
    "                wemakedf['채널'] = '위메프'\n",
    "                wemakedf = wemakedf[['채널','index','상품명', '상품ID', '가격', '판매자', '광고여부']]\n",
    "            except:\n",
    "                errorlst.append({'브랜드': br,'채널':'위메프','키워드':brandkeyword[br][jojo]})\n",
    "                wemakedf = pd.DataFrame()\n",
    "\n",
    "            street.reset_index(inplace=True)\n",
    "            auction.reset_index(inplace=True)\n",
    "            gmarket.reset_index(inplace=True)\n",
    "            coupang.reset_index(inplace=True)\n",
    "            keyworddf = pd.concat([street, auction, gmarket, coupang])\n",
    "            keyworddf['index'] = keyworddf['index'].apply(lambda x: x+1)\n",
    "            keyworddf = pd.concat([keyworddf,naverqq,tmondf,wemakedf])\n",
    "            keyworddf['날짜'] = datetime.now().strftime(\"%y-%m-%d\")\n",
    "            keyworddf = keyworddf[['날짜','채널','index','상품명', '상품ID', '가격', '판매자', '광고여부']]\n",
    "            keyworddf.columns = ['날짜','채널','순위','상품명', '상품ID', '가격', '판매자', '광고여부']\n",
    "\n",
    "                \n",
    "\n",
    "            keyworddf.to_excel(writer, sheet_name = '{}'.format(keyword), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea5180a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
