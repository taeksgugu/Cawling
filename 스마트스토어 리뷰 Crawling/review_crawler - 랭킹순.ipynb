{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로운 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url을 입력하세요\n",
      "https://smartstore.naver.com/ggoorrtem/products/5896164323\n",
      "크롤링할 페이지 수를 입력하세요\n",
      "257\n",
      "저장파일명을 입력하세요\n",
      "형모님1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onrik\\AppData\\Local\\Temp/ipykernel_24588/2800197038.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = Chrome('C:\\\\Users\\\\onrik\\\\chromedriver.exe')\n",
      "C:\\Users\\onrik\\AppData\\Local\\Temp/ipykernel_24588/2800197038.py:34: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath('//*[@id=\"_productTabContainer\"]/div/div[3]/ul/li[2]/a').click()\n",
      "C:\\Users\\onrik\\AppData\\Local\\Temp/ipykernel_24588/2800197038.py:36: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[1]/div[1]/ul/li[1]/a').click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 페이지 크롤링 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onrik\\AppData\\Local\\Temp/ipykernel_24588/2800197038.py:77: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[2]/div/div/a[{}]'.format(counter)).click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 페이지 크롤링 시작\n",
      "3 페이지 크롤링 시작\n",
      "4 페이지 크롤링 시작\n",
      "5 페이지 크롤링 시작\n",
      "6 페이지 크롤링 시작\n",
      "7 페이지 크롤링 시작\n",
      "8 페이지 크롤링 시작\n",
      "9 페이지 크롤링 시작\n",
      "10 페이지 크롤링 시작\n",
      "11 페이지 크롤링 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onrik\\AppData\\Local\\Temp/ipykernel_24588/2800197038.py:86: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[2]/div/div/a[{}]'.format(counter)).click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 페이지 크롤링 시작\n",
      "13 페이지 크롤링 시작\n",
      "14 페이지 크롤링 시작\n",
      "15 페이지 크롤링 시작\n",
      "16 페이지 크롤링 시작\n",
      "17 페이지 크롤링 시작\n",
      "18 페이지 크롤링 시작\n",
      "19 페이지 크롤링 시작\n",
      "20 페이지 크롤링 시작\n",
      "21 페이지 크롤링 시작\n",
      "22 페이지 크롤링 시작\n",
      "23 페이지 크롤링 시작\n",
      "24 페이지 크롤링 시작\n",
      "25 페이지 크롤링 시작\n",
      "26 페이지 크롤링 시작\n",
      "27 페이지 크롤링 시작\n",
      "28 페이지 크롤링 시작\n",
      "29 페이지 크롤링 시작\n",
      "30 페이지 크롤링 시작\n",
      "31 페이지 크롤링 시작\n",
      "32 페이지 크롤링 시작\n",
      "33 페이지 크롤링 시작\n",
      "34 페이지 크롤링 시작\n",
      "35 페이지 크롤링 시작\n",
      "36 페이지 크롤링 시작\n",
      "37 페이지 크롤링 시작\n",
      "38 페이지 크롤링 시작\n",
      "39 페이지 크롤링 시작\n",
      "40 페이지 크롤링 시작\n",
      "41 페이지 크롤링 시작\n",
      "42 페이지 크롤링 시작\n",
      "43 페이지 크롤링 시작\n",
      "44 페이지 크롤링 시작\n",
      "45 페이지 크롤링 시작\n",
      "46 페이지 크롤링 시작\n",
      "47 페이지 크롤링 시작\n",
      "48 페이지 크롤링 시작\n",
      "49 페이지 크롤링 시작\n",
      "50 페이지 크롤링 시작\n",
      "51 페이지 크롤링 시작\n",
      "52 페이지 크롤링 시작\n",
      "53 페이지 크롤링 시작\n",
      "54 페이지 크롤링 시작\n",
      "55 페이지 크롤링 시작\n",
      "56 페이지 크롤링 시작\n",
      "57 페이지 크롤링 시작\n",
      "58 페이지 크롤링 시작\n",
      "59 페이지 크롤링 시작\n",
      "60 페이지 크롤링 시작\n",
      "61 페이지 크롤링 시작\n",
      "62 페이지 크롤링 시작\n",
      "63 페이지 크롤링 시작\n",
      "64 페이지 크롤링 시작\n",
      "65 페이지 크롤링 시작\n",
      "66 페이지 크롤링 시작\n",
      "67 페이지 크롤링 시작\n",
      "68 페이지 크롤링 시작\n",
      "69 페이지 크롤링 시작\n",
      "70 페이지 크롤링 시작\n",
      "71 페이지 크롤링 시작\n",
      "72 페이지 크롤링 시작\n",
      "73 페이지 크롤링 시작\n",
      "74 페이지 크롤링 시작\n",
      "75 페이지 크롤링 시작\n",
      "76 페이지 크롤링 시작\n",
      "77 페이지 크롤링 시작\n",
      "78 페이지 크롤링 시작\n",
      "79 페이지 크롤링 시작\n",
      "80 페이지 크롤링 시작\n",
      "81 페이지 크롤링 시작\n",
      "82 페이지 크롤링 시작\n",
      "83 페이지 크롤링 시작\n",
      "84 페이지 크롤링 시작\n",
      "85 페이지 크롤링 시작\n",
      "86 페이지 크롤링 시작\n",
      "87 페이지 크롤링 시작\n",
      "88 페이지 크롤링 시작\n",
      "89 페이지 크롤링 시작\n",
      "90 페이지 크롤링 시작\n",
      "91 페이지 크롤링 시작\n",
      "92 페이지 크롤링 시작\n",
      "93 페이지 크롤링 시작\n",
      "94 페이지 크롤링 시작\n",
      "95 페이지 크롤링 시작\n",
      "96 페이지 크롤링 시작\n",
      "97 페이지 크롤링 시작\n",
      "98 페이지 크롤링 시작\n",
      "99 페이지 크롤링 시작\n",
      "100 페이지 크롤링 시작\n",
      "101 페이지 크롤링 시작\n",
      "102 페이지 크롤링 시작\n",
      "103 페이지 크롤링 시작\n",
      "104 페이지 크롤링 시작\n",
      "105 페이지 크롤링 시작\n",
      "106 페이지 크롤링 시작\n",
      "107 페이지 크롤링 시작\n",
      "108 페이지 크롤링 시작\n",
      "109 페이지 크롤링 시작\n",
      "110 페이지 크롤링 시작\n",
      "111 페이지 크롤링 시작\n",
      "112 페이지 크롤링 시작\n",
      "113 페이지 크롤링 시작\n",
      "114 페이지 크롤링 시작\n",
      "115 페이지 크롤링 시작\n",
      "116 페이지 크롤링 시작\n",
      "117 페이지 크롤링 시작\n",
      "118 페이지 크롤링 시작\n",
      "119 페이지 크롤링 시작\n",
      "120 페이지 크롤링 시작\n",
      "121 페이지 크롤링 시작\n",
      "122 페이지 크롤링 시작\n",
      "123 페이지 크롤링 시작\n",
      "124 페이지 크롤링 시작\n",
      "125 페이지 크롤링 시작\n",
      "126 페이지 크롤링 시작\n",
      "127 페이지 크롤링 시작\n",
      "128 페이지 크롤링 시작\n",
      "129 페이지 크롤링 시작\n",
      "130 페이지 크롤링 시작\n",
      "131 페이지 크롤링 시작\n",
      "132 페이지 크롤링 시작\n",
      "133 페이지 크롤링 시작\n",
      "134 페이지 크롤링 시작\n",
      "135 페이지 크롤링 시작\n",
      "136 페이지 크롤링 시작\n",
      "137 페이지 크롤링 시작\n",
      "138 페이지 크롤링 시작\n",
      "139 페이지 크롤링 시작\n",
      "140 페이지 크롤링 시작\n",
      "141 페이지 크롤링 시작\n",
      "142 페이지 크롤링 시작\n",
      "143 페이지 크롤링 시작\n",
      "144 페이지 크롤링 시작\n",
      "145 페이지 크롤링 시작\n",
      "146 페이지 크롤링 시작\n",
      "147 페이지 크롤링 시작\n",
      "148 페이지 크롤링 시작\n",
      "149 페이지 크롤링 시작\n",
      "150 페이지 크롤링 시작\n",
      "151 페이지 크롤링 시작\n",
      "152 페이지 크롤링 시작\n",
      "153 페이지 크롤링 시작\n",
      "154 페이지 크롤링 시작\n",
      "155 페이지 크롤링 시작\n",
      "156 페이지 크롤링 시작\n",
      "157 페이지 크롤링 시작\n",
      "158 페이지 크롤링 시작\n",
      "159 페이지 크롤링 시작\n",
      "160 페이지 크롤링 시작\n",
      "161 페이지 크롤링 시작\n",
      "162 페이지 크롤링 시작\n",
      "163 페이지 크롤링 시작\n",
      "164 페이지 크롤링 시작\n",
      "165 페이지 크롤링 시작\n",
      "166 페이지 크롤링 시작\n",
      "167 페이지 크롤링 시작\n",
      "168 페이지 크롤링 시작\n",
      "169 페이지 크롤링 시작\n",
      "170 페이지 크롤링 시작\n",
      "171 페이지 크롤링 시작\n",
      "172 페이지 크롤링 시작\n",
      "173 페이지 크롤링 시작\n",
      "174 페이지 크롤링 시작\n",
      "175 페이지 크롤링 시작\n",
      "176 페이지 크롤링 시작\n",
      "177 페이지 크롤링 시작\n",
      "178 페이지 크롤링 시작\n",
      "179 페이지 크롤링 시작\n",
      "180 페이지 크롤링 시작\n",
      "181 페이지 크롤링 시작\n",
      "182 페이지 크롤링 시작\n",
      "183 페이지 크롤링 시작\n",
      "184 페이지 크롤링 시작\n",
      "185 페이지 크롤링 시작\n",
      "186 페이지 크롤링 시작\n",
      "187 페이지 크롤링 시작\n",
      "188 페이지 크롤링 시작\n",
      "189 페이지 크롤링 시작\n",
      "190 페이지 크롤링 시작\n",
      "191 페이지 크롤링 시작\n",
      "192 페이지 크롤링 시작\n",
      "193 페이지 크롤링 시작\n",
      "194 페이지 크롤링 시작\n",
      "195 페이지 크롤링 시작\n",
      "196 페이지 크롤링 시작\n",
      "197 페이지 크롤링 시작\n",
      "198 페이지 크롤링 시작\n",
      "199 페이지 크롤링 시작\n",
      "200 페이지 크롤링 시작\n",
      "201 페이지 크롤링 시작\n",
      "202 페이지 크롤링 시작\n",
      "203 페이지 크롤링 시작\n",
      "204 페이지 크롤링 시작\n",
      "205 페이지 크롤링 시작\n",
      "206 페이지 크롤링 시작\n",
      "207 페이지 크롤링 시작\n",
      "208 페이지 크롤링 시작\n",
      "209 페이지 크롤링 시작\n",
      "210 페이지 크롤링 시작\n",
      "211 페이지 크롤링 시작\n",
      "212 페이지 크롤링 시작\n",
      "213 페이지 크롤링 시작\n",
      "214 페이지 크롤링 시작\n",
      "215 페이지 크롤링 시작\n",
      "216 페이지 크롤링 시작\n",
      "217 페이지 크롤링 시작\n",
      "218 페이지 크롤링 시작\n",
      "219 페이지 크롤링 시작\n",
      "220 페이지 크롤링 시작\n",
      "221 페이지 크롤링 시작\n",
      "222 페이지 크롤링 시작\n",
      "223 페이지 크롤링 시작\n",
      "224 페이지 크롤링 시작\n",
      "225 페이지 크롤링 시작\n",
      "226 페이지 크롤링 시작\n",
      "227 페이지 크롤링 시작\n",
      "228 페이지 크롤링 시작\n",
      "229 페이지 크롤링 시작\n",
      "230 페이지 크롤링 시작\n",
      "231 페이지 크롤링 시작\n",
      "232 페이지 크롤링 시작\n",
      "233 페이지 크롤링 시작\n",
      "234 페이지 크롤링 시작\n",
      "235 페이지 크롤링 시작\n",
      "236 페이지 크롤링 시작\n",
      "237 페이지 크롤링 시작\n",
      "238 페이지 크롤링 시작\n",
      "239 페이지 크롤링 시작\n",
      "240 페이지 크롤링 시작\n",
      "241 페이지 크롤링 시작\n",
      "242 페이지 크롤링 시작\n",
      "243 페이지 크롤링 시작\n",
      "244 페이지 크롤링 시작\n",
      "245 페이지 크롤링 시작\n",
      "246 페이지 크롤링 시작\n",
      "247 페이지 크롤링 시작\n",
      "248 페이지 크롤링 시작\n",
      "249 페이지 크롤링 시작\n",
      "250 페이지 크롤링 시작\n",
      "251 페이지 크롤링 시작\n",
      "252 페이지 크롤링 시작\n",
      "253 페이지 크롤링 시작\n",
      "254 페이지 크롤링 시작\n",
      "255 페이지 크롤링 시작\n",
      "256 페이지 크롤링 시작\n",
      "257 페이지 크롤링 시작\n",
      "끝!\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print('url을 입력하세요') #크롤링 할 링크 입력\n",
    "site_url = input()\n",
    "print('크롤링할 페이지 수를 입력하세요') #(네이버 리뷰 수 / 20) -> 올림\n",
    "page = int(input())\n",
    "print('저장파일명을 입력하세요')\n",
    "file_name=input()\n",
    "review_df=pd.DataFrame(columns=['id','passwd','리뷰','별점'])\n",
    "\n",
    "# driver=webdriver.Firefox(executable_path='/Users/parkjaeho/Desktop/온누리아이코리아/테크팀/5. Dump/geckodriver')\n",
    "driver = Chrome('C:\\\\Users\\\\onrik\\\\chromedriver.exe')\n",
    "driver.get(site_url)\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Wait to load page\n",
    "    time.sleep(3.5)\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"_productTabContainer\"]/div/div[3]/ul/li[2]/a').click()\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[1]/div[1]/ul/li[1]/a').click()\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "reviewer=[]\n",
    "star_point=[]\n",
    "review_content=[]\n",
    "date = []\n",
    "counter =3\n",
    "page_num = 1\n",
    "for i in range(page):\n",
    "    print(page_num,'페이지 크롤링 시작')\n",
    "    time.sleep(1)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    review = soup.find('ul', class_='TsOLil1PRz')\n",
    "    r = review.select('li > div > div > div > div > div > div > div > div > span')\n",
    "    n = review.select('li > div > div > div > div > div > div > div > div > div > strong')\n",
    "    d = review.select('li > div > div > div > div > div > div > div > div > div > span')\n",
    "    s = review.select('li > div > div > div > div > div > div > div > div > div > em')\n",
    "    for ns in n:\n",
    "        name = ns.text\n",
    "        reviewer.append(name)\n",
    "    for rs in r:\n",
    "        review = rs.text\n",
    "        if review == 'BEST' or review =='재구매' or review == '한달사용기':\n",
    "            pass\n",
    "        else:\n",
    "            review_content.append(review)\n",
    "    for ss in s:\n",
    "        star=ss.text\n",
    "        star_point.append(star)\n",
    "    for dd in d:\n",
    "        if dd.text == '평점':\n",
    "            pass\n",
    "        else:\n",
    "            dates = dd.text\n",
    "            date.append(dates)\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[2]/div/div/a[{}]'.format(counter)).click()       \n",
    "        counter += 1\n",
    "        page_num += 1\n",
    "        time.sleep(2)\n",
    "    except (NoSuchElementException, ElementNotInteractableException):\n",
    "        if page_num >= page:\n",
    "            print('끝!')\n",
    "        elif (counter)%13 == 0:\n",
    "            counter = 3\n",
    "            driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[2]/div/div/a[{}]'.format(counter)).click()       \n",
    "            counter += 1\n",
    "            page_num += 1\n",
    "    time.sleep(2)\n",
    "final=zip(reviewer, review_content, star_point, date)\n",
    "for i in final:\n",
    "    idc = i[0][:10]\n",
    "    reviewc=i[1]\n",
    "    starc=int(i[2])\n",
    "    dates = str(i[3])\n",
    "    review_df = review_df.append(pd.DataFrame([[idc,1111,reviewc,starc, dates]], columns=['id','passwd','리뷰','별점', '날짜']))\n",
    "review_df\n",
    "review_df.to_excel('./{}.xlsx'.format(file_name),index=False)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=zip(reviewer, review_content, star_point, date)\n",
    "for i in final:\n",
    "    idc = i[0][:10]\n",
    "    reviewc=i[1]\n",
    "    starc=int(i[2])\n",
    "    dates = str(i[3])\n",
    "    review_df = review_df.append(pd.DataFrame([[idc,1111,reviewc,starc, dates]], columns=['id','passwd','리뷰','별점', '날짜']))\n",
    "review_df\n",
    "review_df.to_excel('./{}.xlsx'.format(file_name),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shopping.naver.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url을 입력하세요\n",
      "https://shopping.naver.com/fresh/directfarm/stores/100656726/products/4838959293\n",
      "크롤링할 페이지 수를 입력하세요\n",
      "500\n",
      "저장파일명을 입력하세요\n",
      "train_1\n"
     ]
    },
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <a href=\"javascript:void(0)\" class=\"_309aEs16P9 N=a:rev*s.srank\" role=\"radio\" aria-checked=\"true\">...</a> is not clickable at point (738, 6). Other element would receive the click: <div class=\"_13jaAjXOM3\" style=\"display: block;\" id=\"_productTabContainer\">...</div>\n  (Session info: chrome=100.0.4896.127)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-8f51bc423e14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//*[@id=\"REVIEW\"]/div/div[3]/div/div[1]/div[1]/ul/li[1]/a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <a href=\"javascript:void(0)\" class=\"_309aEs16P9 N=a:rev*s.srank\" role=\"radio\" aria-checked=\"true\">...</a> is not clickable at point (738, 6). Other element would receive the click: <div class=\"_13jaAjXOM3\" style=\"display: block;\" id=\"_productTabContainer\">...</div>\n  (Session info: chrome=100.0.4896.127)\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print('url을 입력하세요') #크롤링 할 링크 입력\n",
    "site_url = input()\n",
    "print('크롤링할 페이지 수를 입력하세요') #(네이버 리뷰 수 / 20) -> 올림\n",
    "page = int(input())\n",
    "print('저장파일명을 입력하세요')\n",
    "file_name=input()\n",
    "review_df=pd.DataFrame(columns=['id','passwd','리뷰','별점'])\n",
    "\n",
    "# driver=webdriver.Firefox(executable_path='/Users/parkjaeho/Desktop/온누리아이코리아/테크팀/5. Dump/geckodriver')\n",
    "driver = Chrome('C:\\\\Users\\\\onrik\\\\chromedriver.exe')\n",
    "driver.get(site_url)\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Wait to load page\n",
    "    time.sleep(3.5)\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"_productTabContainer\"]/div/div[3]/ul/li[3]/a').click()\n",
    "\n",
    "time.sleep(3)\n",
    "driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[1]/div[1]/ul/li[1]/a').click()\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "reviewer=[]\n",
    "star_point=[]\n",
    "review_content=[]\n",
    "date = []\n",
    "counter =3\n",
    "page_num = 1\n",
    "for i in range(page):\n",
    "    print(page_num,'페이지 크롤링 시작')\n",
    "    time.sleep(1)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    review = soup.find('ul', class_='_1iaDS5tcmC')\n",
    "    r = review.select('li > div > div > div > div > div > div > div > div > span')\n",
    "    n = review.select('li > div > div > div > div > div > div > div > div > div > strong')\n",
    "    d = review.select('li > div > div > div > div > div > div > div > div > div > span')\n",
    "    s = review.select('li > div > div > div > div > div > div > div > div > div > em')\n",
    "    for ns in n:\n",
    "        name = ns.text\n",
    "        reviewer.append(name)\n",
    "    for rs in r:\n",
    "        review = rs.text\n",
    "        if review == 'BEST' or review =='재구매' or review == '한달사용기':\n",
    "            pass\n",
    "        else:\n",
    "            review_content.append(review)\n",
    "    for ss in s:\n",
    "        star=ss.text\n",
    "        star_point.append(star)\n",
    "    for dd in d:\n",
    "        if dd.text == '평점':\n",
    "            pass\n",
    "        else:\n",
    "            dates = dd.text\n",
    "            date.append(dates)\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[2]/a[{}]'.format(counter)).click()  \n",
    "\n",
    "        counter += 1\n",
    "        page_num += 1\n",
    "        time.sleep(2)\n",
    "    except (NoSuchElementException, ElementNotInteractableException):\n",
    "        if page_num >= page:\n",
    "            print('끝!')\n",
    "        elif (counter)%13 == 0:\n",
    "            counter = 3\n",
    "            driver.find_element_by_xpath('//*[@id=\"REVIEW\"]/div/div[3]/div/div[2]/a[{}]'.format(counter)).click()       \n",
    "            counter += 1\n",
    "            page_num += 1\n",
    "    time.sleep(2)\n",
    "final=zip(reviewer, review_content, star_point, date)\n",
    "for i in final:\n",
    "    idc = i[0][:10]\n",
    "    reviewc=i[1]\n",
    "    starc=int(i[2])\n",
    "    dates = str(i[3])\n",
    "    review_df = review_df.append(pd.DataFrame([[idc,1111,reviewc,starc, dates]], columns=['id','passwd','리뷰','별점', '날짜']))\n",
    "review_df\n",
    "review_df.to_excel('./{}.xlsx'.format(file_name),index=False)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>passwd</th>\n",
       "      <th>리뷰</th>\n",
       "      <th>별점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, passwd, 리뷰, 별점]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
